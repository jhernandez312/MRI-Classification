{"cells":[{"cell_type":"markdown","metadata":{"id":"JOn6x461VbE1"},"source":["# ***Classification of MRI scans for dementia patients (wow!)***\n","\n","Group members:\n","\n","\n","*   John Fortner, jfortner8\n","*   Jessica Hernandez, jhernandez312\n","\n"]},{"cell_type":"markdown","source":["**Introduction**\n","\n","With the advent of MRI technology, researchers are becoming better and better at understanding how the human brain functions, and what kinds of damage have what sympotmatic effects. Using machine learning techniques, we intend to use MRI images of a variety of patients with different extents of dementia in order to train a classifier that can estimate the extent of dementia progression in a given patient using an MRI scan.\n","\n","We will attempt to classify images into 4 categories, assocaited with one the following states: NotDemented, VeryMildDemented, MildDemented, or ModerateDemented. Using this classifier, we can predict given an MRI scan to what extent an individual is likely affected by Alzheimer's, making accurate prediction of onset and access to appropriate treatments easier to obtain."],"metadata":{"id":"qKqg06KMdHU6"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"MCr-KoXCRtH-"},"outputs":[],"source":["import os\n","import numpy as numnum\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","\n","import tensorflow as tf\n","\n","import skimage\n","from skimage import color\n","from skimage import io\n","import torch\n","import torch.nn as nn\n","from torch.autograd import Variable\n","import torch.optim  as optim\n","from torchvision import datasets, models, transforms, utils\n","import torch.nn.functional as F\n","from torchvision.datasets import MNIST\n","from torch.utils.data import DataLoader\n","\n","from sklearn.feature_extraction import text\n","from sklearn.model_selection import train_test_split\n","\n","\n","#! mkdir ~/.kaggle\n","#! cp kaggle.json ~/.kaggle/\n","#! chmod 600 ~/.kaggle/kaggle.json\n","#! kaggle datasets download datasets/tourist55/alzheimers-dataset-4-class-of-images\n","#! unzip alzheimers-dataset-4-class-of-images.zip"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6926,"status":"ok","timestamp":1658914798169,"user":{"displayName":"Jessica Hernandez","userId":"06284171727800282285"},"user_tz":-120},"id":"RCuW64tjtSXB","outputId":"5bc7c555-3a02-4c31-f2dd-0e80829a4fd8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.64.0)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (6.1.2)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n","Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2022.6.15)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n"]}],"source":["! pip install kaggle"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_58UnoOPsJq2"},"outputs":[],"source":["#!rm -r ~/.kaggle\n","! mkdir ~/.kaggle/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5OjHw1VzuLIS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658914807015,"user_tz":-120,"elapsed":322,"user":{"displayName":"Jessica Hernandez","userId":"06284171727800282285"}},"outputId":"6ea1c56d-542d-4b72-82bf-3c479bd1c3c5"},"outputs":[{"output_type":"stream","name":"stdout","text":["mv: cannot stat './kaggle.json': No such file or directory\n"]}],"source":["!mv ./kaggle.json ~/.kaggle/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b2N237rBuV2W","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658914808269,"user_tz":-120,"elapsed":257,"user":{"displayName":"Jessica Hernandez","userId":"06284171727800282285"}},"outputId":"6350000c-6ade-4001-8f5b-8a1a84df4af2"},"outputs":[{"output_type":"stream","name":"stdout","text":["chmod: cannot access '/root/.kaggle/kaggle.json': No such file or directory\n"]}],"source":["!chmod 600 ~/.kaggle/kaggle.json"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RHfJob03ud3W","executionInfo":{"status":"ok","timestamp":1658875058689,"user_tz":-120,"elapsed":2260,"user":{"displayName":"Jessica Hernandez","userId":"06284171727800282285"}},"outputId":"cff18b2a-ff52-493f-8bd6-b8c93cffb243"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading alzheimers-dataset-4-class-of-images.zip to /content\n"," 73% 25.0M/34.1M [00:00<00:00, 56.8MB/s]\n","100% 34.1M/34.1M [00:00<00:00, 62.6MB/s]\n"]}],"source":[" ! kaggle datasets download tourist55/alzheimers-dataset-4-class-of-images"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B_kb-qDsvefL"},"outputs":[],"source":["#%%capture\n","!unzip alzheimers-dataset-4-class-of-images.zip"]},{"cell_type":"markdown","metadata":{"id":"AtLSKdz7qNc3"},"source":["# Code\n"]},{"cell_type":"code","source":["train_dataset = datasets.ImageFolder(root = 'Alzheimer_s Dataset/train', transform=transforms.Compose([transforms.ToTensor(), transforms.Grayscale(num_output_channels=1)]))\n","test_dataset = datasets.ImageFolder('Alzheimer_s Dataset/test', transform=transforms.Compose([transforms.ToTensor(), transforms.Grayscale(num_output_channels=1)]))\n","\n","numDataPoints = len(train_dataset)\n","num_classes = 4\n","\n","\n","\n","# We have our data which is imbalanced\n","# We intend to create an array of weights corresponding to each sampler\n","# We can then use this array to create a WeightedRandomSampler, which will balance our samples\n","print(train_dataset[0][0].shape)\n","\n","#img = numnum.copy(train_dataset[0][0])\n","# shifted_train_dataset = numnum.moveaxis(train_dataset,1, -1)\n","\n","# gray_train_dataset = color.rgb2gray(shifted_train_dataset)\n","# print(gray_train_dataset.shape)\n","# plt.imshow(gray_train_dataset[0][0], cmap='magma')\n","\n","\n","#This creates an array to store all of the labels in the same order they appear as the images\n","labels = numnum.ndarray(len(train_dataset))\n","for data_ind in range(len(train_dataset)):\n","  class_num = train_dataset[data_ind][1]\n","  labels[data_ind] = class_num\n","\n","labels = labels.astype(int)\n","print(labels)\n","\n","#This loop creates another array that stores the number of times each label appears\n","class_sample_count = numnum.array([len(numnum.where(labels == t)[0]) for t in numnum.unique(labels)])\n","print(class_sample_count)\n","\n","#This array holds the appropriate weight for each label according to the class with which it is associated\n","weight = 1.0 / class_sample_count\n","print(weight)\n","\n","#This array holds the appropriate weight (unnormalized) for each datapoint\n","datapoint_weights = numnum.array([weight[i] for i in labels])\n","#datapoint_weights /= num_classes\n","torch.from_numpy(datapoint_weights)\n","\n","#This creates the appropriate weighted sampler\n","weighted_sampler = torch.utils.data.WeightedRandomSampler(datapoint_weights, len(datapoint_weights))\n","print(weighted_sampler)\n","\n","#This creates the DataLoaders, using the weighted sampler for the train_loader\n","train_loader = DataLoader(train_dataset, batch_size=12, num_workers=1, sampler=weighted_sampler)\n","test_loader = DataLoader(test_dataset, batch_size=12, num_workers=1, shuffle = True)\n","\n","print(\"Dataloaders created!\")\n","\n","\n","# for i, (data, target) in enumerate(train_loader):\n","#     print (\"batch index {}, 0/1/2/3: {}/{}/{}/{}\".format(\n","#         i,\n","#         len(numnum.where(target.numpy() == 0)[0]),\n","#         len(numnum.where(target.numpy() == 1)[0]),\n","#         len(numnum.where(target.numpy() == 2)[0]),\n","#         len(numnum.where(target.numpy() == 3)[0])))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3fgBTqYkIMry","executionInfo":{"status":"ok","timestamp":1658875075405,"user_tz":-120,"elapsed":6129,"user":{"displayName":"Jessica Hernandez","userId":"06284171727800282285"}},"outputId":"725344fc-ee90-49c2-9d12-1e6cf9a7efd5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 208, 176])\n","[0 0 0 ... 3 3 3]\n","[ 717   52 2560 1792]\n","[0.0013947  0.01923077 0.00039063 0.00055804]\n","<torch.utils.data.sampler.WeightedRandomSampler object at 0x7f01b7bb1f10>\n","Dataloaders created!\n"]}]},{"cell_type":"code","source":["#Now we can do the model stuff!!!\n","class CONV_NET(nn.Module):\n","  def __init__(self, big_dropout_rate = 0.0, small_dropout_rate = 0.0, input_size = (176*208*1), num_classes = 4):\n","    super().__init__()\n","\n","    self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 6, kernel_size = 5)\n","    self.relu = nn.ReLU()\n","    self.conv2 = nn.Conv2d(in_channels = 6, out_channels = 15, kernel_size = 5)\n","    self.linear1 = nn.Linear(30135, 2340)\n","    self.linear2 = nn.Linear(2340, 420)\n","    self.linear3 = nn.Linear(420, num_classes)\n","    self.pool = nn.MaxPool2d(2, stride = 2)\n","    self.drop_out_of_school = nn.Dropout(big_dropout_rate)\n","    self.drop_out_of_prek = nn.Dropout(small_dropout_rate)\n","\n","\n","  def forward(self, x):\n","    x = self.pool(self.relu(self.conv1(x)))\n","    x = self.pool(self.relu(self.conv2(x)))\n","    x = self.drop_out_of_school(torch.flatten(x, 1))\n","    x = self.drop_out_of_prek(self.relu(self.linear1(x)))\n","    x = self.relu(self.linear2(x))\n","    x = self.linear3(x)\n","    return x"],"metadata":{"id":"m6O1M4HUBxk5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#TRAINING THE MODEL\n","def train(model, train_loader, test_loader, num_epochs = 10):\n","\n","  optimizer = optim.Adamax(model.parameters(), lr = .003)\n","  loss_func = nn.CrossEntropyLoss()\n","\n","\n","  #run the stuff\n","  for epoch in range(num_epochs):\n","    model.train()\n","    for i, data in enumerate(train_loader, 0):\n","\n","      inputs, labels = data\n","\n","      out = model.forward(inputs)\n","      #print(\"LABELS\", labels)\n","      #print(out.argmax(dim=1, keepdim=True))\n","      loss = loss_func(out, labels)\n","      optimizer.zero_grad()\n","      loss.backward()\n","      optimizer.step()\n","\n","    print(\"epoch number\", epoch + 1, \"complete\")\n","    print(\"Training accuracy:\", test(model, train_loader))\n","    print(\"Testing accuracy:\", test(model, test_loader))\n","    print()\n","\n","  #maybe test after each epoch?\n","\n","  # Process is complete.\n","  print('Training process has finished.')\n","\n",""],"metadata":{"id":"53K16IIWDwZl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#TESTING THE MODEL\n","def test(model, test_loader):\n","    model.eval()\n","    correct = 0\n","    with torch.no_grad():\n","        for data, target in test_loader:\n","            output = model(data)\n","            #print(output)\n","\n","            # Retrieve the index associated with the highest probability\n","            pred_i = numnum.argmax(output)\n","            pred = output.argmax(dim=1, keepdim=True)\n","            #print(pred)\n","            correct += pred.eq(target.view_as(pred)).sum().item()\n","\n","    #return 100.0 * correct / len(test_loader.dataset)\n","\n","    #print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n","    #    correct, len(test_loader.dataset),\n","    #    100.0 * correct / len(test_loader.dataset)))\n","    return '{}/{} ({:.0f}%)\\n'.format(\n","        correct, len(test_loader.dataset),\n","        100.0 * correct / len(test_loader.dataset))"],"metadata":{"id":"o5qk21erEL4x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#now we actually run the model\n","alz_conv_model = CONV_NET(big_dropout_rate = 0.8, small_dropout_rate = 0.45)\n","train(alz_conv_model, train_loader, test_loader, num_epochs = 50)\n","test(alz_conv_model, test_loader)\n","from google.colab import output\n","#output.eval_js('new Audio(\"https://upload.wikimedia.org/wikipedia/commons/7/71/EAT_-_06_-_Touch_a_Clown_in_the_Frightness.ogg\").play()')\n","output.eval_js('new Audio(\"https://upload.wikimedia.org/wikipedia/commons/0/0a/Bach_-_cantata_140._2._recitative.ogg\").play()')"],"metadata":{"id":"UZlWn4smEcX9","colab":{"base_uri":"https://localhost:8080/"},"outputId":"1e7e1da5-3940-4fff-b847-4e75fcb3a157"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch number 1 complete\n","Training accuracy: 2770/5121 (54%)\n","\n","Testing accuracy: 256/1279 (20%)\n","\n","\n","epoch number 2 complete\n","Training accuracy: 3737/5121 (73%)\n","\n","Testing accuracy: 659/1279 (52%)\n","\n","\n","epoch number 3 complete\n","Training accuracy: 3985/5121 (78%)\n","\n","Testing accuracy: 593/1279 (46%)\n","\n","\n","epoch number 4 complete\n","Training accuracy: 4382/5121 (86%)\n","\n","Testing accuracy: 619/1279 (48%)\n","\n","\n","epoch number 5 complete\n","Training accuracy: 4667/5121 (91%)\n","\n","Testing accuracy: 679/1279 (53%)\n","\n","\n","epoch number 6 complete\n","Training accuracy: 4757/5121 (93%)\n","\n","Testing accuracy: 717/1279 (56%)\n","\n","\n","epoch number 7 complete\n","Training accuracy: 4760/5121 (93%)\n","\n","Testing accuracy: 629/1279 (49%)\n","\n","\n","epoch number 8 complete\n","Training accuracy: 4851/5121 (95%)\n","\n","Testing accuracy: 730/1279 (57%)\n","\n","\n","epoch number 9 complete\n","Training accuracy: 5006/5121 (98%)\n","\n","Testing accuracy: 762/1279 (60%)\n","\n","\n","epoch number 10 complete\n","Training accuracy: 5038/5121 (98%)\n","\n","Testing accuracy: 802/1279 (63%)\n","\n","\n","epoch number 11 complete\n","Training accuracy: 5063/5121 (99%)\n","\n","Testing accuracy: 687/1279 (54%)\n","\n","\n","epoch number 12 complete\n","Training accuracy: 5024/5121 (98%)\n","\n","Testing accuracy: 782/1279 (61%)\n","\n","\n","epoch number 13 complete\n","Training accuracy: 5100/5121 (100%)\n","\n","Testing accuracy: 773/1279 (60%)\n","\n","\n","epoch number 14 complete\n","Training accuracy: 5110/5121 (100%)\n","\n","Testing accuracy: 747/1279 (58%)\n","\n","\n","epoch number 15 complete\n","Training accuracy: 5109/5121 (100%)\n","\n","Testing accuracy: 810/1279 (63%)\n","\n","\n","epoch number 16 complete\n","Training accuracy: 5111/5121 (100%)\n","\n","Testing accuracy: 812/1279 (63%)\n","\n","\n","epoch number 17 complete\n","Training accuracy: 5112/5121 (100%)\n","\n","Testing accuracy: 781/1279 (61%)\n","\n","\n","epoch number 18 complete\n","Training accuracy: 5121/5121 (100%)\n","\n","Testing accuracy: 823/1279 (64%)\n","\n","\n","epoch number 19 complete\n","Training accuracy: 5120/5121 (100%)\n","\n","Testing accuracy: 798/1279 (62%)\n","\n","\n","epoch number 20 complete\n","Training accuracy: 5121/5121 (100%)\n","\n","Testing accuracy: 804/1279 (63%)\n","\n","\n","epoch number 21 complete\n","Training accuracy: 5119/5121 (100%)\n","\n","Testing accuracy: 822/1279 (64%)\n","\n","\n","epoch number 22 complete\n","Training accuracy: 5121/5121 (100%)\n","\n","Testing accuracy: 829/1279 (65%)\n","\n","\n","epoch number 23 complete\n","Training accuracy: 5120/5121 (100%)\n","\n","Testing accuracy: 821/1279 (64%)\n","\n","\n","epoch number 24 complete\n","Training accuracy: 5121/5121 (100%)\n","\n","Testing accuracy: 849/1279 (66%)\n","\n","\n","epoch number 25 complete\n","Training accuracy: 5121/5121 (100%)\n","\n","Testing accuracy: 826/1279 (65%)\n","\n","\n","epoch number 26 complete\n","Training accuracy: 5121/5121 (100%)\n","\n","Testing accuracy: 825/1279 (65%)\n","\n","\n"]}]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}